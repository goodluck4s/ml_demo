{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lstm 生成模型  anna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以参照官方文档  这个也是生成模型   \n",
    "https://tensorflow.google.cn/tutorials/text/text_generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "cpus = tf.config.experimental.list_physical_devices(device_type='CPU')\n",
    "print(gpus, cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1985223\n",
      "198522\n"
     ]
    }
   ],
   "source": [
    "with open('../data/anna.txt', 'r') as f:\n",
    "    text=f.read()\n",
    "print(len(text))\n",
    "text=text[:int(len(text)/10)]\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(text)\n",
    "vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
    "int_to_vocab = dict(enumerate(vocab))\n",
    "encoded = np.array([vocab_to_int[c] for c in text], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 26, 20, 46, 32, 25, 62,  8,  3, 58, 58, 58, 16, 20, 46, 46, 15,\n",
       "        8, 39, 20, 24, 40,  0, 40, 25, 29,  8, 20, 62, 25,  8, 20,  0,  0,\n",
       "        8, 20,  0, 40, 55, 25,  4,  8, 25, 41, 25, 62, 15,  8, 23, 57, 26,\n",
       "       20, 46, 46, 15,  8, 39, 20, 24, 40,  0, 15,  8, 40, 29,  8, 23, 57,\n",
       "       26, 20, 46, 46, 15,  8, 40, 57,  8, 40, 32, 29,  8,  7, 63, 57, 58,\n",
       "       63, 20, 15, 68, 58, 58, 28, 41, 25, 62, 15, 32, 26, 40, 57])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198522\n",
      "198522\n",
      "198521\n",
      "198522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([26, 20, 46, 32, 25, 62,  8,  3, 58, 58, 58, 16, 20, 46, 46, 15,  8,\n",
       "       39, 20, 24, 40,  0, 40, 25, 29,  8, 20, 62, 25,  8, 20,  0,  0,  8,\n",
       "       20,  0, 40, 55, 25,  4,  8, 25, 41, 25, 62, 15,  8, 23, 57, 26, 20,\n",
       "       46, 46, 15,  8, 39, 20, 24, 40,  0, 15,  8, 40, 29,  8, 23, 57, 26,\n",
       "       20, 46, 46, 15,  8, 40, 57,  8, 40, 32, 29,  8,  7, 63, 57, 58, 63,\n",
       "       20, 15, 68, 58, 58, 28, 41, 25, 62, 15, 32, 26, 40, 57, 56])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(text))\n",
    "print(len(encoded))\n",
    "\n",
    "encoded_train=encoded[1:]\n",
    "print(len(encoded_train))\n",
    "encoded_train=np.append(encoded_train,0)\n",
    "print(len(encoded_train))\n",
    "encoded_train[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100         # Sequences per batch\n",
    "num_steps = 100\n",
    "lstm_size = 800         # Size of hidden layers in LSTMs\n",
    "learning_rate = 0.002    # Learning rate\n",
    "keep_prob = 0.5         # Dropout keep probability\n",
    "vocab_size=len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(encoded)/(batch_size*num_steps))*(batch_size*num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1900, 100, 75)\n",
      "(1900, 100, 75)\n"
     ]
    }
   ],
   "source": [
    "def reshap_onehot_arr(arr,time_steps,cls_num):\n",
    "    arr=arr[:int(len(encoded)/(batch_size*num_steps))*(batch_size*num_steps)]\n",
    "    arr=np.reshape(arr,(-1,time_steps))\n",
    "    arr=tf.keras.utils.to_categorical(arr,cls_num,dtype='int')\n",
    "    print(arr.shape)\n",
    "    return arr\n",
    "\n",
    "train_x=reshap_onehot_arr(encoded,num_steps,vocab_size)\n",
    "train_y=reshap_onehot_arr(encoded_train,num_steps,vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " https://huhuhang.com/post/machine-learning/lstm-return-sequences-state  解释两个重要参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1677b0fd2a72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstateful_flag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_sequences_flag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "def build_model(batch_size,stateful_flag,return_sequences_flag):\n",
    "    model = keras.Sequential([\n",
    "        layers.LSTM(lstm_size,\n",
    "#                     dropout=keep_prob,\n",
    "#                     recurrent_dropout=keep_prob,\n",
    "                    return_sequences=return_sequences_flag,\n",
    "                    stateful=stateful_flag,\n",
    "                   batch_input_shape=[batch_size,None,vocab_size]),\n",
    "        layers.Dense(vocab_size,activation=\"softmax\")\n",
    "\n",
    "    \n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "model=build_model(batch_size=batch_size,stateful_flag=True,return_sequences_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate),\n",
    "                 loss=keras.losses.CategoricalCrossentropy(),\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (100, None, 800)          2803200   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (100, None, 75)           60075     \n",
      "=================================================================\n",
      "Total params: 2,863,275\n",
      "Trainable params: 2,863,275\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 检查点保存至的目录\n",
    "checkpoint_dir = './training_checkpoints/lstm_anna/'\n",
    "\n",
    "# 检查点的文件名\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"lstm_anna_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1900 samples\n",
      "Epoch 1/10\n",
      "1900/1900 [==============================] - 61s 32ms/sample - loss: 1.9599 - accuracy: 0.4338\n",
      "Epoch 2/10\n",
      "1900/1900 [==============================] - 61s 32ms/sample - loss: 1.9036 - accuracy: 0.4493\n",
      "Epoch 3/10\n",
      "1900/1900 [==============================] - 62s 33ms/sample - loss: 1.8602 - accuracy: 0.4587\n",
      "Epoch 4/10\n",
      "1900/1900 [==============================] - 62s 33ms/sample - loss: 1.8202 - accuracy: 0.4704\n",
      "Epoch 5/10\n",
      "1900/1900 [==============================] - 62s 33ms/sample - loss: 1.7811 - accuracy: 0.4809\n",
      "Epoch 6/10\n",
      "1900/1900 [==============================] - 62s 33ms/sample - loss: 1.7450 - accuracy: 0.4904\n",
      "Epoch 7/10\n",
      "1900/1900 [==============================] - 62s 33ms/sample - loss: 1.7079 - accuracy: 0.5004\n",
      "Epoch 8/10\n",
      "1900/1900 [==============================] - 62s 32ms/sample - loss: 1.6671 - accuracy: 0.5117\n",
      "Epoch 9/10\n",
      "1900/1900 [==============================] - 62s 32ms/sample - loss: 1.6265 - accuracy: 0.5237\n",
      "Epoch 10/10\n",
      "1900/1900 [==============================] - 62s 33ms/sample - loss: 1.5961 - accuracy: 0.5317\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y, batch_size=batch_size, epochs=10,callbacks=[checkpoint_callback])\n",
    "# 将整个模型保存为HDF5文件\n",
    "model.save('./model/anna_keras_lstm_epochs2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints/lstm_anna/lstm_anna_10'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (1, 800)                  2803200   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (1, 75)                   60075     \n",
      "=================================================================\n",
      "Total params: 2,863,275\n",
      "Trainable params: 2,863,275\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_pre =build_model(batch_size=1,stateful_flag=True,return_sequences_flag=False)\n",
    "model_pre.load_weights(tf.train.latest_checkpoint(checkpoint_dir)) #只加载最后一次的weight\n",
    "model_pre.build(tf.TensorShape([1,None,vocab_size]))\n",
    "model_pre.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1]\n",
      "  [2]\n",
      "  [3]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([1,2,3])\n",
    "a=a.reshape([1,-1,1])\n",
    "print(a)\n",
    "a=tf.keras.utils.to_categorical(a,vocab_size,dtype='float32')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.00387782 0.00355583 0.01432575 0.03160315 0.01879684 0.02237747\n",
      "  0.00575899 0.0288036  0.00415679 0.02998908 0.01219524 0.00915078\n",
      "  0.01883724 0.00723327 0.02751429 0.0326223  0.00659324 0.0050552\n",
      "  0.01413766 0.00802052 0.009037   0.00329559 0.0085423  0.00902359\n",
      "  0.00354656 0.00900195 0.00137365 0.00551215 0.01088765 0.0070126\n",
      "  0.00450935 0.02868954 0.00686476 0.00442277 0.00793611 0.02432618\n",
      "  0.01993652 0.0193146  0.01064909 0.00216354 0.02402181 0.00458153\n",
      "  0.00907346 0.02575792 0.01002721 0.01868439 0.00286023 0.00877257\n",
      "  0.00915062 0.01241996 0.00579801 0.014286   0.01473222 0.00993283\n",
      "  0.01437463 0.05806882 0.00682235 0.00163117 0.02170659 0.01180592\n",
      "  0.02033466 0.02918465 0.00502624 0.00554483 0.00932612 0.00893214\n",
      "  0.00709701 0.00959793 0.00777258 0.00645924 0.00599416 0.00825742\n",
      "  0.02460239 0.03221976 0.03449202]], shape=(1, 75), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999999202555045"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict_res = model_pre(a)\n",
    "print(test_predict_res)\n",
    "sum(test_predict_res.numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.058068816\n",
      "tf.Tensor(55, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([55, 58, 35, 35, 55, 73,  5, 73, 14, 28, 55, 37, 61, 17, 55, 61,  9,\n",
       "       35, 65, 72])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_distrubtion = test_predict_res.numpy().flatten()\n",
    "print(max(pre_distrubtion))\n",
    "print(tf.argmax(pre_distrubtion))\n",
    "np.random.choice(np.array(range(pre_distrubtion.shape[0])), 20, replace=True, p=pre_distrubtion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20 24]\n",
      "input_eval (1, 2, 75)\n",
      "predictions (1, 75)\n",
      "predicted_char p\n",
      "predictions (1, 75)\n",
      "predicted_char o\n",
      "predictions (1, 75)\n",
      "predicted_char i\n",
      "predictions (1, 75)\n",
      "predicted_char n\n",
      "predictions (1, 75)\n",
      "predicted_char g\n",
      "predictions (1, 75)\n",
      "predicted_char \n",
      "\n",
      "predictions (1, 75)\n",
      "predicted_char a\n",
      "predictions (1, 75)\n",
      "predicted_char t\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char o\n",
      "predictions (1, 75)\n",
      "predicted_char w\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char ,\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char f\n",
      "predictions (1, 75)\n",
      "predicted_char o\n",
      "predictions (1, 75)\n",
      "predicted_char r\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char s\n",
      "predictions (1, 75)\n",
      "predicted_char i\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char q\n",
      "predictions (1, 75)\n",
      "predicted_char u\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char s\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char x\n",
      "predictions (1, 75)\n",
      "predicted_char p\n",
      "predictions (1, 75)\n",
      "predicted_char r\n",
      "predictions (1, 75)\n",
      "predicted_char i\n",
      "predictions (1, 75)\n",
      "predicted_char t\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char r\n",
      "predictions (1, 75)\n",
      "predicted_char o\n",
      "predictions (1, 75)\n",
      "predicted_char n\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char p\n",
      "predictions (1, 75)\n",
      "predicted_char r\n",
      "predictions (1, 75)\n",
      "predicted_char a\n",
      "predictions (1, 75)\n",
      "predicted_char t\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char c\n",
      "predictions (1, 75)\n",
      "predicted_char t\n",
      "predictions (1, 75)\n",
      "predicted_char l\n",
      "predictions (1, 75)\n",
      "predicted_char y\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char t\n",
      "predictions (1, 75)\n",
      "predicted_char o\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char n\n",
      "predictions (1, 75)\n",
      "predicted_char a\n",
      "predictions (1, 75)\n",
      "predicted_char t\n",
      "predictions (1, 75)\n",
      "predicted_char u\n",
      "predictions (1, 75)\n",
      "predicted_char r\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char ,\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char a\n",
      "predictions (1, 75)\n",
      "predicted_char n\n",
      "predictions (1, 75)\n",
      "predicted_char a\n",
      "predictions (1, 75)\n",
      "predicted_char t\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char h\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char r\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char i\n",
      "predictions (1, 75)\n",
      "predicted_char d\n",
      "predictions (1, 75)\n",
      "predicted_char n\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char p\n",
      "predictions (1, 75)\n",
      "predicted_char ,\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char a\n",
      "predictions (1, 75)\n",
      "predicted_char n\n",
      "predictions (1, 75)\n",
      "predicted_char d\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char t\n",
      "predictions (1, 75)\n",
      "predicted_char h\n",
      "predictions (1, 75)\n",
      "predicted_char o\n",
      "predictions (1, 75)\n",
      "predicted_char u\n",
      "predictions (1, 75)\n",
      "predicted_char t\n",
      "predictions (1, 75)\n",
      "predicted_char h\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char d\n",
      "predictions (1, 75)\n",
      "predicted_char o\n",
      "predictions (1, 75)\n",
      "predicted_char w\n",
      "predictions (1, 75)\n",
      "predicted_char n\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char o\n",
      "predictions (1, 75)\n",
      "predicted_char n\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char n\n",
      "predictions (1, 75)\n",
      "predicted_char r\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char .\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char S\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ampoing\\nat owe, for sieques expriteron pratectly to nature, anat her idnep, and thouth down on enre. S'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # 评估步骤（用学习过的模型生成文本）\n",
    "\n",
    "    # 要生成的字符个数\n",
    "    num_generate = 100\n",
    "\n",
    "    # 将起始字符串转换为数字（向量化）\n",
    "    input_eval = np.array([vocab_to_int[s] for s in start_string])\n",
    "    print(input_eval)\n",
    "    input_eval = input_eval.reshape([1,-1,1])\n",
    "    input_eval=tf.keras.utils.to_categorical(input_eval,vocab_size,dtype='float32')\n",
    "    print(\"input_eval\",input_eval.shape)\n",
    "\n",
    "    # 空字符串用于存储结果\n",
    "    text_generated = []\n",
    "\n",
    "    # 低温度会生成更可预测的文本\n",
    "    # 较高温度会生成更令人惊讶的文本\n",
    "    # 可以通过试验以找到最好的设定\n",
    "    temperature = 1.0\n",
    "\n",
    "    # 这里批大小为 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        \n",
    "        predictions = model(input_eval)\n",
    "        print(\"predictions\",predictions.shape)        \n",
    "#         predicted_id = tf.argmax(predictions.numpy().flatten()).numpy()\n",
    "#         print(\"predicted_id\",predicted_id)\n",
    "        predictions_distr = predictions.numpy().flatten()\n",
    "        index_list = np.array(range(predictions_distr.shape[0]))\n",
    "        predicted_id = np.random.choice(index_list, 1, replace=True, p=predictions_distr)\n",
    "        pre_char= int_to_vocab[list(predicted_id)[0]]\n",
    "        print(\"predicted_char\",pre_char)\n",
    "        text_generated.append(pre_char)\n",
    "        \n",
    "        input_eval = np.array([vocab_to_int[s] for s in pre_char])\n",
    "        input_eval = input_eval.reshape([1,-1,1])\n",
    "        input_eval=tf.keras.utils.to_categorical(input_eval,vocab_size,dtype='float32')\n",
    "\n",
    "    return (start_string + ''.join(text_generated))\n",
    "\n",
    "generate_text(model_pre,\"am\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
