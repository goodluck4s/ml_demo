{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lstm 生成模型  anna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以参照官方文档  这个也是生成模型   \n",
    "https://tensorflow.google.cn/tutorials/text/text_generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "cpus = tf.config.experimental.list_physical_devices(device_type='CPU')\n",
    "print(gpus, cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1985223\n",
      "198522\n"
     ]
    }
   ],
   "source": [
    "with open('../data/anna.txt', 'r') as f:\n",
    "    text=f.read()\n",
    "print(len(text))\n",
    "text=text[:int(len(text)/10)]\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(text)\n",
    "vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
    "int_to_vocab = dict(enumerate(vocab))\n",
    "encoded = np.array([vocab_to_int[c] for c in text], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([58, 70, 24, 63, 35, 48, 37, 49, 19, 59, 59, 59,  5, 24, 63, 63, 71,\n",
       "       49, 18, 24, 73, 32,  3, 32, 48, 67, 49, 24, 37, 48, 49, 24,  3,  3,\n",
       "       49, 24,  3, 32, 27, 48, 53, 49, 48, 33, 48, 37, 71, 49, 14, 34, 70,\n",
       "       24, 63, 63, 71, 49, 18, 24, 73, 32,  3, 71, 49, 32, 67, 49, 14, 34,\n",
       "       70, 24, 63, 63, 71, 49, 32, 34, 49, 32, 35, 67, 49, 54, 51, 34, 59,\n",
       "       51, 24, 71, 72, 59, 59, 20, 33, 48, 37, 71, 35, 70, 32, 34],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198522\n",
      "198522\n",
      "198521\n",
      "198522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([70, 24, 63, 35, 48, 37, 49, 19, 59, 59, 59,  5, 24, 63, 63, 71, 49,\n",
       "       18, 24, 73, 32,  3, 32, 48, 67, 49, 24, 37, 48, 49, 24,  3,  3, 49,\n",
       "       24,  3, 32, 27, 48, 53, 49, 48, 33, 48, 37, 71, 49, 14, 34, 70, 24,\n",
       "       63, 63, 71, 49, 18, 24, 73, 32,  3, 71, 49, 32, 67, 49, 14, 34, 70,\n",
       "       24, 63, 63, 71, 49, 32, 34, 49, 32, 35, 67, 49, 54, 51, 34, 59, 51,\n",
       "       24, 71, 72, 59, 59, 20, 33, 48, 37, 71, 35, 70, 32, 34, 45])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(text))\n",
    "print(len(encoded))\n",
    "\n",
    "encoded_train=encoded[1:]\n",
    "print(len(encoded_train))\n",
    "encoded_train=np.append(encoded_train,0)\n",
    "print(len(encoded_train))\n",
    "encoded_train[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64         # Sequences per batch\n",
    "num_steps = 128\n",
    "lstm_size = 768         # Size of hidden layers in LSTMs\n",
    "learning_rate = 0.002    # Learning rate\n",
    "keep_prob = 0.5         # Dropout keep probability\n",
    "vocab_size=len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196608"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(encoded)/(batch_size*num_steps))*(batch_size*num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1536, 128, 75)\n",
      "(1536, 128, 75)\n"
     ]
    }
   ],
   "source": [
    "def reshap_onehot_arr(arr,time_steps,cls_num):\n",
    "    arr=arr[:int(len(encoded)/(batch_size*num_steps))*(batch_size*num_steps)]\n",
    "    arr=np.reshape(arr,(-1,time_steps))\n",
    "    arr=tf.keras.utils.to_categorical(arr,cls_num,dtype='int')\n",
    "    print(arr.shape)\n",
    "    return arr\n",
    "\n",
    "train_x=reshap_onehot_arr(encoded,num_steps,vocab_size)\n",
    "train_y=reshap_onehot_arr(encoded_train,num_steps,vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " https://huhuhang.com/post/machine-learning/lstm-return-sequences-state  解释两个重要参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(batch_size,stateful_flag,return_sequences_flag):\n",
    "    model = keras.Sequential([\n",
    "        layers.LSTM(lstm_size,\n",
    "#                     dropout=keep_prob,\n",
    "#                     recurrent_dropout=keep_prob,\n",
    "                    return_sequences=return_sequences_flag,\n",
    "                    stateful=stateful_flag,\n",
    "                   batch_input_shape=[batch_size,None,vocab_size]),\n",
    "        layers.Dense(vocab_size,activation=\"softmax\")\n",
    "\n",
    "    \n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "model=build_model(batch_size=batch_size,stateful_flag=True,return_sequences_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate),\n",
    "                 loss=keras.losses.CategoricalCrossentropy(),\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (64, None, 768)           2592768   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (64, None, 75)            57675     \n",
      "=================================================================\n",
      "Total params: 2,650,443\n",
      "Trainable params: 2,650,443\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 检查点保存至的目录\n",
    "checkpoint_dir = './training_checkpoints/lstm_anna/'\n",
    "\n",
    "# 检查点的文件名\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"lstm_anna_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "24/24 [==============================] - 24s 991ms/step - loss: 2.0102 - accuracy: 0.4244\n",
      "Epoch 2/2\n",
      "24/24 [==============================] - 26s 1s/step - loss: 1.9584 - accuracy: 0.4352\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y, batch_size=batch_size, epochs=2,callbacks=[checkpoint_callback])\n",
    "# 将整个模型保存为HDF5文件\n",
    "# model.save('./model/anna_keras_lstm_epochs2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints/lstm_anna/lstm_anna_2'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (1, 768)                  2592768   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (1, 75)                   57675     \n",
      "=================================================================\n",
      "Total params: 2,650,443\n",
      "Trainable params: 2,650,443\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_pre =build_model(batch_size=1,stateful_flag=True,return_sequences_flag=False)\n",
    "model_pre.load_weights(tf.train.latest_checkpoint(checkpoint_dir)) #只加载最后一次的weight\n",
    "model_pre.build(tf.TensorShape([1,None,vocab_size]))\n",
    "model_pre.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1]\n",
      "  [2]\n",
      "  [3]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([1,2,3])\n",
    "a=a.reshape([1,-1,1])\n",
    "print(a)\n",
    "a=tf.keras.utils.to_categorical(a,vocab_size,dtype='float32')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.00895433 0.00738238 0.00769131 0.02747618 0.00730457 0.01471999\n",
      "  0.01369404 0.00830105 0.00702767 0.00774915 0.01050662 0.01182116\n",
      "  0.0123561  0.00773084 0.02194421 0.00768127 0.00552484 0.00807873\n",
      "  0.01350781 0.00748674 0.01320702 0.00777904 0.00677212 0.00880008\n",
      "  0.01791713 0.01541926 0.01987185 0.00969178 0.00524338 0.01209897\n",
      "  0.00723721 0.01433095 0.02660017 0.00817015 0.00758837 0.0080409\n",
      "  0.00920677 0.0126022  0.00725214 0.01025167 0.01662128 0.00498053\n",
      "  0.00584034 0.02519404 0.00768138 0.0063764  0.01215357 0.0079821\n",
      "  0.03001572 0.036899   0.00911816 0.01187509 0.00731351 0.01568682\n",
      "  0.02076812 0.0088321  0.01563297 0.01285512 0.00996464 0.09136713\n",
      "  0.01781917 0.00736531 0.01339475 0.00621431 0.0073671  0.01313248\n",
      "  0.00719469 0.00862644 0.0073649  0.01096334 0.00678743 0.03276003\n",
      "  0.03979056 0.00860991 0.01043132]], shape=(1, 75), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999999185092747"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict_res = model_pre(a)\n",
    "print(test_predict_res)\n",
    "sum(test_predict_res.numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09136713\n",
      "tf.Tensor(59, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([46, 31, 11, 59, 58, 49, 64, 59, 71, 21, 70, 14, 72, 23, 65, 72, 31,\n",
       "       37, 65, 20])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_distrubtion = test_predict_res.numpy().flatten()\n",
    "print(max(pre_distrubtion))\n",
    "print(tf.argmax(pre_distrubtion))\n",
    "np.random.choice(np.array(range(pre_distrubtion.shape[0])), 20, replace=True, p=pre_distrubtion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24 73]\n",
      "input_eval (1, 2, 75)\n",
      "predictions (1, 75)\n",
      "predicted_char r\n",
      "predictions (1, 75)\n",
      "predicted_char .\n",
      "predictions (1, 75)\n",
      "predicted_char z\n",
      "predictions (1, 75)\n",
      "predicted_char \"\n",
      "predictions (1, 75)\n",
      "predicted_char \n",
      "\n",
      "predictions (1, 75)\n",
      "predicted_char d\n",
      "predictions (1, 75)\n",
      "predicted_char \"\n",
      "predictions (1, 75)\n",
      "predicted_char W\n",
      "predictions (1, 75)\n",
      "predicted_char h\n",
      "predictions (1, 75)\n",
      "predicted_char l\n",
      "predictions (1, 75)\n",
      "predicted_char l\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char w\n",
      "predictions (1, 75)\n",
      "predicted_char o\n",
      "predictions (1, 75)\n",
      "predicted_char o\n",
      "predictions (1, 75)\n",
      "predicted_char d\n",
      "predictions (1, 75)\n",
      "predicted_char ?\n",
      "predictions (1, 75)\n",
      "predicted_char \"\n",
      "predictions (1, 75)\n",
      "predicted_char \n",
      "\n",
      "predictions (1, 75)\n",
      "predicted_char \n",
      "\n",
      "predictions (1, 75)\n",
      "predicted_char \"\n",
      "predictions (1, 75)\n",
      "predicted_char S\n",
      "predictions (1, 75)\n",
      "predicted_char h\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char a\n",
      "predictions (1, 75)\n",
      "predicted_char l\n",
      "predictions (1, 75)\n",
      "predicted_char l\n",
      "predictions (1, 75)\n",
      "predicted_char i\n",
      "predictions (1, 75)\n",
      "predicted_char c\n",
      "predictions (1, 75)\n",
      "predicted_char h\n",
      "predictions (1, 75)\n",
      "predicted_char ,\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char b\n",
      "predictions (1, 75)\n",
      "predicted_char u\n",
      "predictions (1, 75)\n",
      "predicted_char t\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char h\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char r\n",
      "predictions (1, 75)\n",
      "predicted_char a\n",
      "predictions (1, 75)\n",
      "predicted_char n\n",
      "predictions (1, 75)\n",
      "predicted_char t\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char d\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char s\n",
      "predictions (1, 75)\n",
      "predicted_char i\n",
      "predictions (1, 75)\n",
      "predicted_char s\n",
      "predictions (1, 75)\n",
      "predicted_char ?\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char Y\n",
      "predictions (1, 75)\n",
      "predicted_char o\n",
      "predictions (1, 75)\n",
      "predicted_char u\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char t\n",
      "predictions (1, 75)\n",
      "predicted_char h\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char r\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char b\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char c\n",
      "predictions (1, 75)\n",
      "predicted_char i\n",
      "predictions (1, 75)\n",
      "predicted_char n\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char o\n",
      "predictions (1, 75)\n",
      "predicted_char f\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char o\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char h\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char p\n",
      "predictions (1, 75)\n",
      "predicted_char a\n",
      "predictions (1, 75)\n",
      "predicted_char s\n",
      "predictions (1, 75)\n",
      "predicted_char k\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char d\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char n\n",
      "predictions (1, 75)\n",
      "predicted_char t\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char h\n",
      "predictions (1, 75)\n",
      "predicted_char a\n",
      "predictions (1, 75)\n",
      "predicted_char m\n",
      "predictions (1, 75)\n",
      "predicted_char  \n",
      "predictions (1, 75)\n",
      "predicted_char v\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char r\n",
      "predictions (1, 75)\n",
      "predicted_char r\n",
      "predictions (1, 75)\n",
      "predicted_char o\n",
      "predictions (1, 75)\n",
      "predicted_char m\n",
      "predictions (1, 75)\n",
      "predicted_char b\n",
      "predictions (1, 75)\n",
      "predicted_char e\n",
      "predictions (1, 75)\n",
      "predicted_char g\n",
      "predictions (1, 75)\n",
      "predicted_char  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'amr.z\"\\nd\"Whll wood?\"\\n\\n\"She eallich, but heranted sis? You ther becine of o he paskedent ham verrombeg '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # 评估步骤（用学习过的模型生成文本）\n",
    "\n",
    "    # 要生成的字符个数\n",
    "    num_generate = 100\n",
    "\n",
    "    # 将起始字符串转换为数字（向量化）\n",
    "    input_eval = np.array([vocab_to_int[s] for s in start_string])\n",
    "    print(input_eval)\n",
    "    input_eval = input_eval.reshape([1,-1,1])\n",
    "    input_eval=tf.keras.utils.to_categorical(input_eval,vocab_size,dtype='float32')\n",
    "    print(\"input_eval\",input_eval.shape)\n",
    "\n",
    "    # 空字符串用于存储结果\n",
    "    text_generated = []\n",
    "\n",
    "    # 低温度会生成更可预测的文本\n",
    "    # 较高温度会生成更令人惊讶的文本\n",
    "    # 可以通过试验以找到最好的设定\n",
    "    temperature = 1.0\n",
    "\n",
    "    # 这里批大小为 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        \n",
    "        predictions = model(input_eval)\n",
    "        print(\"predictions\",predictions.shape)        \n",
    "#         predicted_id = tf.argmax(predictions.numpy().flatten()).numpy()\n",
    "#         print(\"predicted_id\",predicted_id)\n",
    "        predictions_distr = predictions.numpy().flatten()\n",
    "        index_list = np.array(range(predictions_distr.shape[0]))\n",
    "        predicted_id = np.random.choice(index_list, 1, replace=True, p=predictions_distr)\n",
    "        pre_char= int_to_vocab[list(predicted_id)[0]]\n",
    "        print(\"predicted_char\",pre_char)\n",
    "        text_generated.append(pre_char)\n",
    "        \n",
    "        input_eval = np.array([vocab_to_int[s] for s in pre_char])\n",
    "        input_eval = input_eval.reshape([1,-1,1])\n",
    "        input_eval=tf.keras.utils.to_categorical(input_eval,vocab_size,dtype='float32')\n",
    "\n",
    "    return (start_string + ''.join(text_generated))\n",
    "\n",
    "generate_text(model_pre,\"am\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
