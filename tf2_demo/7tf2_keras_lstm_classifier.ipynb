{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lstm 做文本分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1数据处理     \n",
    "bow模型并不适用于这类场景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_cut=10000\n",
    "emb_size=64\n",
    "lstm_size=64\n",
    "batch_size=64\n",
    "seq_cut=400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import collections\n",
    "import os\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 20000\n"
     ]
    }
   ],
   "source": [
    "pos_list=[]\n",
    "with open('../data/Imdb/pos_all.txt','r',encoding='utf8')as f:\n",
    "    line=f.readlines()\n",
    "    pos_list.extend(line)\n",
    "neg_list=[]\n",
    "with open('../data/Imdb/neg_all.txt','r',encoding='utf8')as f:\n",
    "    line=f.readlines()\n",
    "    neg_list.extend(line)\n",
    "\n",
    "pos_list = pos_list[:bow_cut]\n",
    "neg_list = neg_list[:bow_cut]\n",
    "\n",
    "#创建标签\n",
    "label=[1 for i in range(bow_cut)]\n",
    "label.extend([0 for i in range(bow_cut)])\n",
    "#评论内容整合\n",
    "pos_list.extend(neg_list)\n",
    "content=pos_list\n",
    "print(len(content),len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/qianlai/nltk_data'\n    - '/opt/anaconda3/nltk_data'\n    - '/opt/anaconda3/share/nltk_data'\n    - '/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b82fbb54b0aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcon\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \"\"\"\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     return [\n\u001b[1;32m    146\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/qianlai/nltk_data'\n    - '/opt/anaconda3/nltk_data'\n    - '/opt/anaconda3/share/nltk_data'\n    - '/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "seq=[]\n",
    "seqtence=[]\n",
    "stop_words={}\n",
    "for con in content:\n",
    "    words=nltk.word_tokenize(con)    \n",
    "    line=[]\n",
    "    for word in words:\n",
    "        if word.isalpha() and word not in stop_words:\n",
    "            line.append(word)   \n",
    "    seq.append(line)\n",
    "    seqtence.extend(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 2592518\n"
     ]
    }
   ],
   "source": [
    "print(len(seq),len(seqtence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词表大小 80809\n"
     ]
    }
   ],
   "source": [
    "vocab = set(seqtence)\n",
    "print(\"词表大小\",len(vocab))\n",
    "vocab_to_int = {c: i+1 for i, c in enumerate(vocab)}\n",
    "int_to_vocab = {i+1: c for i, c in enumerate(vocab)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 400)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = []\n",
    "for a_seq in seq:\n",
    "    a_encoded = [vocab_to_int[c] for c in a_seq]\n",
    "    if len(a_encoded)>seq_cut:\n",
    "        a_encoded=a_encoded[:seq_cut]\n",
    "    else:\n",
    "        a_encoded=np.pad(a_encoded, (0,seq_cut-len(a_encoded)), 'constant', constant_values=0)\n",
    "    encoded.append(a_encoded)\n",
    "encoded=np.array(encoded)\n",
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label=np.array(label)\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41139,  8319, 45647, ...,     0,     0,     0],\n",
       "       [60922, 45901,  2091, ...,     0,     0,     0],\n",
       "       [ 8968,  1336, 30216, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [46564,  3300, 52547, ...,     0,     0,     0],\n",
       "       [46564,  3300, 78083, ...,     0,     0,     0],\n",
       "       [46564,  3300, 62169, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 64)          5171840   \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,246,209\n",
      "Trainable params: 5,246,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(len(vocab)+1, emb_size),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_size)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/2\n",
      "11776/16000 [=====================>........] - ETA: 16:18 - loss: 0.6956 - accuracy: 0.406 - ETA: 9:53 - loss: 0.6955 - accuracy: 0.382 - ETA: 7:40 - loss: 0.6954 - accuracy: 0.36 - ETA: 6:33 - loss: 0.6953 - accuracy: 0.35 - ETA: 5:53 - loss: 0.6949 - accuracy: 0.38 - ETA: 5:26 - loss: 0.6947 - accuracy: 0.39 - ETA: 5:07 - loss: 0.6945 - accuracy: 0.40 - ETA: 4:51 - loss: 0.6942 - accuracy: 0.42 - ETA: 4:39 - loss: 0.6940 - accuracy: 0.45 - ETA: 4:30 - loss: 0.6938 - accuracy: 0.47 - ETA: 4:23 - loss: 0.6936 - accuracy: 0.49 - ETA: 4:16 - loss: 0.6933 - accuracy: 0.50 - ETA: 4:11 - loss: 0.6931 - accuracy: 0.51 - ETA: 4:06 - loss: 0.6930 - accuracy: 0.52 - ETA: 4:00 - loss: 0.6928 - accuracy: 0.52 - ETA: 3:56 - loss: 0.6927 - accuracy: 0.53 - ETA: 3:53 - loss: 0.6924 - accuracy: 0.53 - ETA: 3:49 - loss: 0.6922 - accuracy: 0.54 - ETA: 3:46 - loss: 0.6921 - accuracy: 0.54 - ETA: 3:42 - loss: 0.6919 - accuracy: 0.54 - ETA: 3:40 - loss: 0.6919 - accuracy: 0.54 - ETA: 3:37 - loss: 0.6918 - accuracy: 0.54 - ETA: 3:35 - loss: 0.6915 - accuracy: 0.55 - ETA: 3:33 - loss: 0.6914 - accuracy: 0.55 - ETA: 3:30 - loss: 0.6913 - accuracy: 0.55 - ETA: 3:29 - loss: 0.6911 - accuracy: 0.55 - ETA: 3:27 - loss: 0.6909 - accuracy: 0.56 - ETA: 3:25 - loss: 0.6908 - accuracy: 0.56 - ETA: 3:23 - loss: 0.6906 - accuracy: 0.56 - ETA: 3:21 - loss: 0.6902 - accuracy: 0.57 - ETA: 3:19 - loss: 0.6899 - accuracy: 0.57 - ETA: 3:18 - loss: 0.6897 - accuracy: 0.57 - ETA: 3:16 - loss: 0.6897 - accuracy: 0.57 - ETA: 3:15 - loss: 0.6897 - accuracy: 0.57 - ETA: 3:13 - loss: 0.6897 - accuracy: 0.57 - ETA: 3:12 - loss: 0.6897 - accuracy: 0.57 - ETA: 3:11 - loss: 0.6894 - accuracy: 0.57 - ETA: 3:09 - loss: 0.6894 - accuracy: 0.57 - ETA: 3:08 - loss: 0.6891 - accuracy: 0.57 - ETA: 3:07 - loss: 0.6888 - accuracy: 0.57 - ETA: 3:05 - loss: 0.6884 - accuracy: 0.58 - ETA: 3:04 - loss: 0.6882 - accuracy: 0.58 - ETA: 3:02 - loss: 0.6880 - accuracy: 0.58 - ETA: 3:01 - loss: 0.6878 - accuracy: 0.58 - ETA: 3:00 - loss: 0.6875 - accuracy: 0.58 - ETA: 2:59 - loss: 0.6874 - accuracy: 0.58 - ETA: 2:57 - loss: 0.6874 - accuracy: 0.58 - ETA: 2:56 - loss: 0.6871 - accuracy: 0.58 - ETA: 2:56 - loss: 0.6869 - accuracy: 0.58 - ETA: 2:54 - loss: 0.6868 - accuracy: 0.58 - ETA: 2:53 - loss: 0.6864 - accuracy: 0.59 - ETA: 2:52 - loss: 0.6860 - accuracy: 0.59 - ETA: 2:51 - loss: 0.6857 - accuracy: 0.59 - ETA: 2:50 - loss: 0.6853 - accuracy: 0.59 - ETA: 2:49 - loss: 0.6853 - accuracy: 0.59 - ETA: 2:48 - loss: 0.6848 - accuracy: 0.59 - ETA: 2:47 - loss: 0.6845 - accuracy: 0.59 - ETA: 2:46 - loss: 0.6842 - accuracy: 0.59 - ETA: 2:45 - loss: 0.6842 - accuracy: 0.59 - ETA: 2:43 - loss: 0.6839 - accuracy: 0.59 - ETA: 2:43 - loss: 0.6837 - accuracy: 0.59 - ETA: 2:41 - loss: 0.6832 - accuracy: 0.60 - ETA: 2:40 - loss: 0.6826 - accuracy: 0.60 - ETA: 2:39 - loss: 0.6824 - accuracy: 0.60 - ETA: 2:38 - loss: 0.6820 - accuracy: 0.60 - ETA: 2:37 - loss: 0.6818 - accuracy: 0.60 - ETA: 2:36 - loss: 0.6818 - accuracy: 0.60 - ETA: 2:35 - loss: 0.6819 - accuracy: 0.60 - ETA: 2:34 - loss: 0.6814 - accuracy: 0.60 - ETA: 2:33 - loss: 0.6813 - accuracy: 0.60 - ETA: 2:32 - loss: 0.6813 - accuracy: 0.60 - ETA: 2:31 - loss: 0.6809 - accuracy: 0.60 - ETA: 2:30 - loss: 0.6806 - accuracy: 0.60 - ETA: 2:30 - loss: 0.6800 - accuracy: 0.60 - ETA: 2:29 - loss: 0.6801 - accuracy: 0.60 - ETA: 2:28 - loss: 0.6800 - accuracy: 0.60 - ETA: 2:27 - loss: 0.6795 - accuracy: 0.60 - ETA: 2:26 - loss: 0.6800 - accuracy: 0.60 - ETA: 2:25 - loss: 0.6800 - accuracy: 0.60 - ETA: 2:24 - loss: 0.6795 - accuracy: 0.60 - ETA: 2:23 - loss: 0.6790 - accuracy: 0.60 - ETA: 2:22 - loss: 0.6785 - accuracy: 0.60 - ETA: 2:22 - loss: 0.6780 - accuracy: 0.60 - ETA: 2:21 - loss: 0.6789 - accuracy: 0.60 - ETA: 2:20 - loss: 0.6788 - accuracy: 0.60 - ETA: 2:19 - loss: 0.6785 - accuracy: 0.60 - ETA: 2:18 - loss: 0.6785 - accuracy: 0.60 - ETA: 2:17 - loss: 0.6787 - accuracy: 0.60 - ETA: 2:16 - loss: 0.6785 - accuracy: 0.60 - ETA: 2:15 - loss: 0.6783 - accuracy: 0.60 - ETA: 2:14 - loss: 0.6787 - accuracy: 0.60 - ETA: 2:14 - loss: 0.6789 - accuracy: 0.60 - ETA: 2:13 - loss: 0.6788 - accuracy: 0.60 - ETA: 2:12 - loss: 0.6786 - accuracy: 0.60 - ETA: 2:11 - loss: 0.6780 - accuracy: 0.60 - ETA: 2:10 - loss: 0.6781 - accuracy: 0.60 - ETA: 2:09 - loss: 0.6777 - accuracy: 0.60 - ETA: 2:08 - loss: 0.6778 - accuracy: 0.60 - ETA: 2:07 - loss: 0.6780 - accuracy: 0.60 - ETA: 2:06 - loss: 0.6777 - accuracy: 0.60 - ETA: 2:05 - loss: 0.6780 - accuracy: 0.60 - ETA: 2:05 - loss: 0.6776 - accuracy: 0.60 - ETA: 2:04 - loss: 0.6771 - accuracy: 0.60 - ETA: 2:03 - loss: 0.6771 - accuracy: 0.60 - ETA: 2:02 - loss: 0.6770 - accuracy: 0.60 - ETA: 2:01 - loss: 0.6766 - accuracy: 0.60 - ETA: 2:00 - loss: 0.6761 - accuracy: 0.60 - ETA: 1:59 - loss: 0.6761 - accuracy: 0.60 - ETA: 1:59 - loss: 0.6763 - accuracy: 0.60 - ETA: 1:58 - loss: 0.6760 - accuracy: 0.60 - ETA: 1:57 - loss: 0.6760 - accuracy: 0.60 - ETA: 1:56 - loss: 0.6759 - accuracy: 0.60 - ETA: 1:55 - loss: 0.6756 - accuracy: 0.60 - ETA: 1:54 - loss: 0.6756 - accuracy: 0.60 - ETA: 1:53 - loss: 0.6753 - accuracy: 0.60 - ETA: 1:52 - loss: 0.6749 - accuracy: 0.61 - ETA: 1:51 - loss: 0.6754 - accuracy: 0.60 - ETA: 1:51 - loss: 0.6755 - accuracy: 0.60 - ETA: 1:50 - loss: 0.6753 - accuracy: 0.60 - ETA: 1:49 - loss: 0.6754 - accuracy: 0.60 - ETA: 1:48 - loss: 0.6754 - accuracy: 0.60 - ETA: 1:47 - loss: 0.6752 - accuracy: 0.60 - ETA: 1:46 - loss: 0.6749 - accuracy: 0.60 - ETA: 1:45 - loss: 0.6743 - accuracy: 0.61 - ETA: 1:44 - loss: 0.6742 - accuracy: 0.61 - ETA: 1:43 - loss: 0.6738 - accuracy: 0.61 - ETA: 1:42 - loss: 0.6735 - accuracy: 0.61 - ETA: 1:42 - loss: 0.6737 - accuracy: 0.61 - ETA: 1:41 - loss: 0.6734 - accuracy: 0.61 - ETA: 1:40 - loss: 0.6733 - accuracy: 0.61 - ETA: 1:39 - loss: 0.6730 - accuracy: 0.61 - ETA: 1:38 - loss: 0.6729 - accuracy: 0.61 - ETA: 1:37 - loss: 0.6727 - accuracy: 0.61 - ETA: 1:36 - loss: 0.6725 - accuracy: 0.61 - ETA: 1:36 - loss: 0.6729 - accuracy: 0.61 - ETA: 1:35 - loss: 0.6723 - accuracy: 0.61 - ETA: 1:34 - loss: 0.6722 - accuracy: 0.61 - ETA: 1:33 - loss: 0.6721 - accuracy: 0.61 - ETA: 1:32 - loss: 0.6718 - accuracy: 0.61 - ETA: 1:31 - loss: 0.6720 - accuracy: 0.61 - ETA: 1:30 - loss: 0.6720 - accuracy: 0.61 - ETA: 1:30 - loss: 0.6722 - accuracy: 0.61 - ETA: 1:29 - loss: 0.6721 - accuracy: 0.61 - ETA: 1:28 - loss: 0.6716 - accuracy: 0.61 - ETA: 1:27 - loss: 0.6718 - accuracy: 0.61 - ETA: 1:26 - loss: 0.6714 - accuracy: 0.61 - ETA: 1:25 - loss: 0.6716 - accuracy: 0.61 - ETA: 1:25 - loss: 0.6717 - accuracy: 0.61 - ETA: 1:24 - loss: 0.6716 - accuracy: 0.61 - ETA: 1:23 - loss: 0.6721 - accuracy: 0.61 - ETA: 1:22 - loss: 0.6721 - accuracy: 0.61 - ETA: 1:21 - loss: 0.6722 - accuracy: 0.61 - ETA: 1:20 - loss: 0.6721 - accuracy: 0.61 - ETA: 1:20 - loss: 0.6719 - accuracy: 0.61 - ETA: 1:19 - loss: 0.6718 - accuracy: 0.61 - ETA: 1:18 - loss: 0.6715 - accuracy: 0.61 - ETA: 1:17 - loss: 0.6714 - accuracy: 0.61 - ETA: 1:16 - loss: 0.6711 - accuracy: 0.61 - ETA: 1:15 - loss: 0.6708 - accuracy: 0.61 - ETA: 1:14 - loss: 0.6705 - accuracy: 0.61 - ETA: 1:14 - loss: 0.6702 - accuracy: 0.61 - ETA: 1:13 - loss: 0.6700 - accuracy: 0.61 - ETA: 1:12 - loss: 0.6699 - accuracy: 0.61 - ETA: 1:11 - loss: 0.6699 - accuracy: 0.61 - ETA: 1:10 - loss: 0.6703 - accuracy: 0.61 - ETA: 1:09 - loss: 0.6704 - accuracy: 0.61 - ETA: 1:09 - loss: 0.6702 - accuracy: 0.61 - ETA: 1:08 - loss: 0.6697 - accuracy: 0.61 - ETA: 1:07 - loss: 0.6698 - accuracy: 0.61 - ETA: 1:06 - loss: 0.6701 - accuracy: 0.61 - ETA: 1:05 - loss: 0.6697 - accuracy: 0.61 - ETA: 1:04 - loss: 0.6693 - accuracy: 0.61 - ETA: 1:04 - loss: 0.6693 - accuracy: 0.61 - ETA: 1:03 - loss: 0.6693 - accuracy: 0.61 - ETA: 1:02 - loss: 0.6691 - accuracy: 0.61 - ETA: 1:01 - loss: 0.6689 - accuracy: 0.61 - ETA: 1:00 - loss: 0.6687 - accuracy: 0.61 - ETA: 59s - loss: 0.6685 - accuracy: 0.6177 - ETA: 58s - loss: 0.6681 - accuracy: 0.618 - ETA: 58s - loss: 0.6683 - accuracy: 0.617 - ETA: 57s - loss: 0.6684 - accuracy: 0.617 - ETA: 56s - loss: 0.6682 - accuracy: 0.617 - ETA: 55s - loss: 0.6682 - accuracy: 0.617 - ETA: 54s - loss: 0.6681 - accuracy: 0.61816000/16000 [==============================] - ETA: 53s - loss: 0.6676 - accuracy: 0.618 - ETA: 53s - loss: 0.6677 - accuracy: 0.618 - ETA: 52s - loss: 0.6677 - accuracy: 0.618 - ETA: 51s - loss: 0.6677 - accuracy: 0.618 - ETA: 50s - loss: 0.6676 - accuracy: 0.618 - ETA: 49s - loss: 0.6674 - accuracy: 0.618 - ETA: 48s - loss: 0.6674 - accuracy: 0.618 - ETA: 48s - loss: 0.6670 - accuracy: 0.618 - ETA: 47s - loss: 0.6674 - accuracy: 0.618 - ETA: 46s - loss: 0.6673 - accuracy: 0.618 - ETA: 45s - loss: 0.6673 - accuracy: 0.617 - ETA: 44s - loss: 0.6674 - accuracy: 0.617 - ETA: 43s - loss: 0.6672 - accuracy: 0.617 - ETA: 43s - loss: 0.6670 - accuracy: 0.618 - ETA: 42s - loss: 0.6670 - accuracy: 0.618 - ETA: 41s - loss: 0.6669 - accuracy: 0.617 - ETA: 40s - loss: 0.6668 - accuracy: 0.617 - ETA: 39s - loss: 0.6669 - accuracy: 0.617 - ETA: 38s - loss: 0.6669 - accuracy: 0.617 - ETA: 38s - loss: 0.6667 - accuracy: 0.617 - ETA: 37s - loss: 0.6667 - accuracy: 0.617 - ETA: 36s - loss: 0.6664 - accuracy: 0.617 - ETA: 35s - loss: 0.6663 - accuracy: 0.617 - ETA: 34s - loss: 0.6662 - accuracy: 0.617 - ETA: 33s - loss: 0.6658 - accuracy: 0.618 - ETA: 33s - loss: 0.6658 - accuracy: 0.618 - ETA: 32s - loss: 0.6657 - accuracy: 0.618 - ETA: 31s - loss: 0.6657 - accuracy: 0.617 - ETA: 30s - loss: 0.6654 - accuracy: 0.618 - ETA: 29s - loss: 0.6650 - accuracy: 0.618 - ETA: 28s - loss: 0.6649 - accuracy: 0.618 - ETA: 28s - loss: 0.6648 - accuracy: 0.618 - ETA: 27s - loss: 0.6643 - accuracy: 0.619 - ETA: 26s - loss: 0.6644 - accuracy: 0.618 - ETA: 25s - loss: 0.6644 - accuracy: 0.618 - ETA: 24s - loss: 0.6642 - accuracy: 0.618 - ETA: 23s - loss: 0.6642 - accuracy: 0.618 - ETA: 23s - loss: 0.6640 - accuracy: 0.618 - ETA: 22s - loss: 0.6637 - accuracy: 0.619 - ETA: 21s - loss: 0.6635 - accuracy: 0.619 - ETA: 20s - loss: 0.6632 - accuracy: 0.619 - ETA: 19s - loss: 0.6630 - accuracy: 0.619 - ETA: 19s - loss: 0.6627 - accuracy: 0.619 - ETA: 18s - loss: 0.6627 - accuracy: 0.619 - ETA: 17s - loss: 0.6626 - accuracy: 0.618 - ETA: 16s - loss: 0.6622 - accuracy: 0.619 - ETA: 15s - loss: 0.6619 - accuracy: 0.619 - ETA: 14s - loss: 0.6620 - accuracy: 0.618 - ETA: 14s - loss: 0.6619 - accuracy: 0.618 - ETA: 13s - loss: 0.6615 - accuracy: 0.618 - ETA: 12s - loss: 0.6611 - accuracy: 0.618 - ETA: 11s - loss: 0.6607 - accuracy: 0.619 - ETA: 10s - loss: 0.6603 - accuracy: 0.619 - ETA: 9s - loss: 0.6600 - accuracy: 0.619 - ETA: 9s - loss: 0.6599 - accuracy: 0.61 - ETA: 8s - loss: 0.6594 - accuracy: 0.61 - ETA: 7s - loss: 0.6592 - accuracy: 0.61 - ETA: 6s - loss: 0.6588 - accuracy: 0.61 - ETA: 5s - loss: 0.6584 - accuracy: 0.61 - ETA: 4s - loss: 0.6587 - accuracy: 0.61 - ETA: 4s - loss: 0.6581 - accuracy: 0.61 - ETA: 3s - loss: 0.6579 - accuracy: 0.61 - ETA: 2s - loss: 0.6577 - accuracy: 0.61 - ETA: 1s - loss: 0.6573 - accuracy: 0.61 - ETA: 0s - loss: 0.6572 - accuracy: 0.61 - 214s 13ms/sample - loss: 0.6567 - accuracy: 0.6189 - val_loss: 0.9140 - val_accuracy: 0.0103\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11904/16000 [=====================>........] - ETA: 3:03 - loss: 0.5531 - accuracy: 0.62 - ETA: 3:08 - loss: 0.5546 - accuracy: 0.60 - ETA: 3:09 - loss: 0.5432 - accuracy: 0.63 - ETA: 3:10 - loss: 0.5437 - accuracy: 0.63 - ETA: 3:09 - loss: 0.5218 - accuracy: 0.65 - ETA: 3:09 - loss: 0.5456 - accuracy: 0.64 - ETA: 3:07 - loss: 0.5475 - accuracy: 0.64 - ETA: 3:07 - loss: 0.5517 - accuracy: 0.62 - ETA: 3:07 - loss: 0.5459 - accuracy: 0.63 - ETA: 3:06 - loss: 0.5483 - accuracy: 0.63 - ETA: 3:05 - loss: 0.5509 - accuracy: 0.62 - ETA: 3:05 - loss: 0.5510 - accuracy: 0.63 - ETA: 3:04 - loss: 0.5505 - accuracy: 0.63 - ETA: 3:03 - loss: 0.5467 - accuracy: 0.64 - ETA: 3:03 - loss: 0.5477 - accuracy: 0.65 - ETA: 3:02 - loss: 0.5481 - accuracy: 0.65 - ETA: 3:01 - loss: 0.5496 - accuracy: 0.65 - ETA: 3:01 - loss: 0.5473 - accuracy: 0.65 - ETA: 3:00 - loss: 0.5472 - accuracy: 0.66 - ETA: 2:59 - loss: 0.5497 - accuracy: 0.66 - ETA: 2:59 - loss: 0.5504 - accuracy: 0.66 - ETA: 2:58 - loss: 0.5495 - accuracy: 0.66 - ETA: 2:57 - loss: 0.5466 - accuracy: 0.67 - ETA: 2:56 - loss: 0.5510 - accuracy: 0.67 - ETA: 2:55 - loss: 0.5494 - accuracy: 0.67 - ETA: 2:55 - loss: 0.5482 - accuracy: 0.68 - ETA: 2:54 - loss: 0.5487 - accuracy: 0.68 - ETA: 2:54 - loss: 0.5478 - accuracy: 0.68 - ETA: 2:54 - loss: 0.5448 - accuracy: 0.68 - ETA: 2:53 - loss: 0.5448 - accuracy: 0.69 - ETA: 2:52 - loss: 0.5430 - accuracy: 0.69 - ETA: 2:52 - loss: 0.5408 - accuracy: 0.69 - ETA: 2:51 - loss: 0.5392 - accuracy: 0.69 - ETA: 2:50 - loss: 0.5378 - accuracy: 0.69 - ETA: 2:50 - loss: 0.5340 - accuracy: 0.70 - ETA: 2:49 - loss: 0.5368 - accuracy: 0.70 - ETA: 2:48 - loss: 0.5337 - accuracy: 0.70 - ETA: 2:48 - loss: 0.5356 - accuracy: 0.70 - ETA: 2:47 - loss: 0.5355 - accuracy: 0.70 - ETA: 2:46 - loss: 0.5353 - accuracy: 0.70 - ETA: 2:45 - loss: 0.5342 - accuracy: 0.71 - ETA: 2:44 - loss: 0.5333 - accuracy: 0.71 - ETA: 2:44 - loss: 0.5299 - accuracy: 0.71 - ETA: 2:43 - loss: 0.5293 - accuracy: 0.71 - ETA: 2:42 - loss: 0.5292 - accuracy: 0.71 - ETA: 2:42 - loss: 0.5309 - accuracy: 0.71 - ETA: 2:41 - loss: 0.5283 - accuracy: 0.72 - ETA: 2:40 - loss: 0.5275 - accuracy: 0.72 - ETA: 2:39 - loss: 0.5275 - accuracy: 0.72 - ETA: 2:39 - loss: 0.5259 - accuracy: 0.72 - ETA: 2:38 - loss: 0.5256 - accuracy: 0.72 - ETA: 2:37 - loss: 0.5248 - accuracy: 0.72 - ETA: 2:36 - loss: 0.5240 - accuracy: 0.73 - ETA: 2:36 - loss: 0.5239 - accuracy: 0.73 - ETA: 2:35 - loss: 0.5223 - accuracy: 0.73 - ETA: 2:34 - loss: 0.5203 - accuracy: 0.73 - ETA: 2:33 - loss: 0.5201 - accuracy: 0.73 - ETA: 2:33 - loss: 0.5191 - accuracy: 0.74 - ETA: 2:32 - loss: 0.5186 - accuracy: 0.74 - ETA: 2:31 - loss: 0.5170 - accuracy: 0.74 - ETA: 2:30 - loss: 0.5157 - accuracy: 0.74 - ETA: 2:30 - loss: 0.5150 - accuracy: 0.74 - ETA: 2:29 - loss: 0.5146 - accuracy: 0.74 - ETA: 2:28 - loss: 0.5136 - accuracy: 0.74 - ETA: 2:27 - loss: 0.5119 - accuracy: 0.75 - ETA: 2:27 - loss: 0.5105 - accuracy: 0.75 - ETA: 2:26 - loss: 0.5100 - accuracy: 0.75 - ETA: 2:25 - loss: 0.5080 - accuracy: 0.75 - ETA: 2:24 - loss: 0.5073 - accuracy: 0.75 - ETA: 2:24 - loss: 0.5083 - accuracy: 0.75 - ETA: 2:23 - loss: 0.5070 - accuracy: 0.75 - ETA: 2:22 - loss: 0.5049 - accuracy: 0.76 - ETA: 2:21 - loss: 0.5037 - accuracy: 0.76 - ETA: 2:20 - loss: 0.5024 - accuracy: 0.76 - ETA: 2:19 - loss: 0.5018 - accuracy: 0.76 - ETA: 2:19 - loss: 0.5005 - accuracy: 0.76 - ETA: 2:18 - loss: 0.5007 - accuracy: 0.76 - ETA: 2:17 - loss: 0.5000 - accuracy: 0.76 - ETA: 2:16 - loss: 0.5000 - accuracy: 0.76 - ETA: 2:15 - loss: 0.4989 - accuracy: 0.76 - ETA: 2:15 - loss: 0.4985 - accuracy: 0.76 - ETA: 2:14 - loss: 0.4969 - accuracy: 0.76 - ETA: 2:13 - loss: 0.4963 - accuracy: 0.76 - ETA: 2:12 - loss: 0.4960 - accuracy: 0.76 - ETA: 2:11 - loss: 0.4962 - accuracy: 0.76 - ETA: 2:11 - loss: 0.4967 - accuracy: 0.76 - ETA: 2:10 - loss: 0.4960 - accuracy: 0.76 - ETA: 2:09 - loss: 0.4959 - accuracy: 0.77 - ETA: 2:08 - loss: 0.4955 - accuracy: 0.77 - ETA: 2:07 - loss: 0.4947 - accuracy: 0.77 - ETA: 2:07 - loss: 0.4934 - accuracy: 0.77 - ETA: 2:06 - loss: 0.4920 - accuracy: 0.77 - ETA: 2:05 - loss: 0.4925 - accuracy: 0.77 - ETA: 2:04 - loss: 0.4919 - accuracy: 0.77 - ETA: 2:04 - loss: 0.4916 - accuracy: 0.77 - ETA: 2:03 - loss: 0.4901 - accuracy: 0.77 - ETA: 2:02 - loss: 0.4891 - accuracy: 0.77 - ETA: 2:01 - loss: 0.4886 - accuracy: 0.77 - ETA: 2:01 - loss: 0.4881 - accuracy: 0.77 - ETA: 2:00 - loss: 0.4875 - accuracy: 0.78 - ETA: 1:59 - loss: 0.4874 - accuracy: 0.78 - ETA: 1:58 - loss: 0.4867 - accuracy: 0.78 - ETA: 1:58 - loss: 0.4859 - accuracy: 0.78 - ETA: 1:57 - loss: 0.4845 - accuracy: 0.78 - ETA: 1:56 - loss: 0.4841 - accuracy: 0.78 - ETA: 1:55 - loss: 0.4837 - accuracy: 0.78 - ETA: 1:54 - loss: 0.4831 - accuracy: 0.78 - ETA: 1:54 - loss: 0.4826 - accuracy: 0.78 - ETA: 1:53 - loss: 0.4815 - accuracy: 0.78 - ETA: 1:52 - loss: 0.4803 - accuracy: 0.78 - ETA: 1:51 - loss: 0.4794 - accuracy: 0.78 - ETA: 1:50 - loss: 0.4779 - accuracy: 0.78 - ETA: 1:50 - loss: 0.4769 - accuracy: 0.79 - ETA: 1:49 - loss: 0.4758 - accuracy: 0.79 - ETA: 1:48 - loss: 0.4752 - accuracy: 0.79 - ETA: 1:47 - loss: 0.4742 - accuracy: 0.79 - ETA: 1:46 - loss: 0.4742 - accuracy: 0.79 - ETA: 1:45 - loss: 0.4735 - accuracy: 0.79 - ETA: 1:45 - loss: 0.4736 - accuracy: 0.79 - ETA: 1:44 - loss: 0.4722 - accuracy: 0.79 - ETA: 1:43 - loss: 0.4710 - accuracy: 0.79 - ETA: 1:42 - loss: 0.4707 - accuracy: 0.79 - ETA: 1:42 - loss: 0.4702 - accuracy: 0.79 - ETA: 1:41 - loss: 0.4694 - accuracy: 0.79 - ETA: 1:40 - loss: 0.4686 - accuracy: 0.79 - ETA: 1:39 - loss: 0.4684 - accuracy: 0.79 - ETA: 1:38 - loss: 0.4686 - accuracy: 0.79 - ETA: 1:38 - loss: 0.4683 - accuracy: 0.79 - ETA: 1:37 - loss: 0.4672 - accuracy: 0.79 - ETA: 1:36 - loss: 0.4669 - accuracy: 0.79 - ETA: 1:35 - loss: 0.4668 - accuracy: 0.79 - ETA: 1:34 - loss: 0.4670 - accuracy: 0.79 - ETA: 1:34 - loss: 0.4670 - accuracy: 0.79 - ETA: 1:33 - loss: 0.4662 - accuracy: 0.79 - ETA: 1:32 - loss: 0.4655 - accuracy: 0.79 - ETA: 1:31 - loss: 0.4649 - accuracy: 0.79 - ETA: 1:30 - loss: 0.4646 - accuracy: 0.79 - ETA: 1:30 - loss: 0.4637 - accuracy: 0.79 - ETA: 1:29 - loss: 0.4631 - accuracy: 0.79 - ETA: 1:28 - loss: 0.4630 - accuracy: 0.79 - ETA: 1:27 - loss: 0.4626 - accuracy: 0.79 - ETA: 1:27 - loss: 0.4620 - accuracy: 0.79 - ETA: 1:26 - loss: 0.4614 - accuracy: 0.80 - ETA: 1:25 - loss: 0.4609 - accuracy: 0.80 - ETA: 1:24 - loss: 0.4604 - accuracy: 0.80 - ETA: 1:24 - loss: 0.4603 - accuracy: 0.80 - ETA: 1:23 - loss: 0.4597 - accuracy: 0.80 - ETA: 1:22 - loss: 0.4591 - accuracy: 0.80 - ETA: 1:21 - loss: 0.4582 - accuracy: 0.80 - ETA: 1:20 - loss: 0.4580 - accuracy: 0.80 - ETA: 1:19 - loss: 0.4568 - accuracy: 0.80 - ETA: 1:19 - loss: 0.4555 - accuracy: 0.80 - ETA: 1:18 - loss: 0.4553 - accuracy: 0.80 - ETA: 1:17 - loss: 0.4546 - accuracy: 0.80 - ETA: 1:16 - loss: 0.4539 - accuracy: 0.80 - ETA: 1:16 - loss: 0.4537 - accuracy: 0.80 - ETA: 1:15 - loss: 0.4526 - accuracy: 0.80 - ETA: 1:14 - loss: 0.4523 - accuracy: 0.80 - ETA: 1:13 - loss: 0.4522 - accuracy: 0.80 - ETA: 1:12 - loss: 0.4516 - accuracy: 0.80 - ETA: 1:11 - loss: 0.4512 - accuracy: 0.80 - ETA: 1:11 - loss: 0.4506 - accuracy: 0.80 - ETA: 1:10 - loss: 0.4500 - accuracy: 0.80 - ETA: 1:09 - loss: 0.4490 - accuracy: 0.80 - ETA: 1:08 - loss: 0.4483 - accuracy: 0.80 - ETA: 1:07 - loss: 0.4470 - accuracy: 0.80 - ETA: 1:07 - loss: 0.4467 - accuracy: 0.80 - ETA: 1:06 - loss: 0.4460 - accuracy: 0.80 - ETA: 1:05 - loss: 0.4452 - accuracy: 0.81 - ETA: 1:04 - loss: 0.4450 - accuracy: 0.80 - ETA: 1:04 - loss: 0.4440 - accuracy: 0.81 - ETA: 1:03 - loss: 0.4437 - accuracy: 0.81 - ETA: 1:02 - loss: 0.4431 - accuracy: 0.81 - ETA: 1:01 - loss: 0.4424 - accuracy: 0.81 - ETA: 1:00 - loss: 0.4418 - accuracy: 0.81 - ETA: 1:00 - loss: 0.4410 - accuracy: 0.81 - ETA: 59s - loss: 0.4408 - accuracy: 0.8119 - ETA: 58s - loss: 0.4402 - accuracy: 0.812 - ETA: 57s - loss: 0.4395 - accuracy: 0.812 - ETA: 56s - loss: 0.4385 - accuracy: 0.813 - ETA: 55s - loss: 0.4378 - accuracy: 0.813 - ETA: 55s - loss: 0.4370 - accuracy: 0.813 - ETA: 54s - loss: 0.4368 - accuracy: 0.814 - ETA: 53s - loss: 0.4364 - accuracy: 0.814 - ETA: 52s - loss: 0.4357 - accuracy: 0.814 - ETA: 51s - loss: 0.4352 - accuracy: 0.8147"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - ETA: 51s - loss: 0.4348 - accuracy: 0.814 - ETA: 50s - loss: 0.4337 - accuracy: 0.815 - ETA: 49s - loss: 0.4334 - accuracy: 0.815 - ETA: 48s - loss: 0.4330 - accuracy: 0.815 - ETA: 47s - loss: 0.4325 - accuracy: 0.815 - ETA: 47s - loss: 0.4320 - accuracy: 0.816 - ETA: 46s - loss: 0.4320 - accuracy: 0.815 - ETA: 45s - loss: 0.4317 - accuracy: 0.816 - ETA: 44s - loss: 0.4313 - accuracy: 0.816 - ETA: 43s - loss: 0.4305 - accuracy: 0.817 - ETA: 42s - loss: 0.4298 - accuracy: 0.817 - ETA: 42s - loss: 0.4304 - accuracy: 0.817 - ETA: 41s - loss: 0.4297 - accuracy: 0.817 - ETA: 40s - loss: 0.4288 - accuracy: 0.818 - ETA: 39s - loss: 0.4283 - accuracy: 0.818 - ETA: 38s - loss: 0.4277 - accuracy: 0.818 - ETA: 38s - loss: 0.4271 - accuracy: 0.819 - ETA: 37s - loss: 0.4266 - accuracy: 0.819 - ETA: 36s - loss: 0.4267 - accuracy: 0.819 - ETA: 35s - loss: 0.4259 - accuracy: 0.819 - ETA: 34s - loss: 0.4254 - accuracy: 0.820 - ETA: 34s - loss: 0.4250 - accuracy: 0.820 - ETA: 33s - loss: 0.4248 - accuracy: 0.820 - ETA: 32s - loss: 0.4241 - accuracy: 0.820 - ETA: 31s - loss: 0.4239 - accuracy: 0.820 - ETA: 30s - loss: 0.4235 - accuracy: 0.821 - ETA: 30s - loss: 0.4229 - accuracy: 0.821 - ETA: 29s - loss: 0.4226 - accuracy: 0.821 - ETA: 28s - loss: 0.4225 - accuracy: 0.821 - ETA: 27s - loss: 0.4220 - accuracy: 0.821 - ETA: 26s - loss: 0.4221 - accuracy: 0.821 - ETA: 26s - loss: 0.4220 - accuracy: 0.821 - ETA: 25s - loss: 0.4211 - accuracy: 0.822 - ETA: 24s - loss: 0.4204 - accuracy: 0.822 - ETA: 23s - loss: 0.4203 - accuracy: 0.822 - ETA: 22s - loss: 0.4198 - accuracy: 0.822 - ETA: 21s - loss: 0.4195 - accuracy: 0.822 - ETA: 21s - loss: 0.4190 - accuracy: 0.823 - ETA: 20s - loss: 0.4187 - accuracy: 0.823 - ETA: 19s - loss: 0.4181 - accuracy: 0.823 - ETA: 18s - loss: 0.4178 - accuracy: 0.823 - ETA: 17s - loss: 0.4174 - accuracy: 0.824 - ETA: 17s - loss: 0.4171 - accuracy: 0.824 - ETA: 16s - loss: 0.4167 - accuracy: 0.824 - ETA: 15s - loss: 0.4162 - accuracy: 0.824 - ETA: 14s - loss: 0.4158 - accuracy: 0.824 - ETA: 13s - loss: 0.4158 - accuracy: 0.824 - ETA: 12s - loss: 0.4151 - accuracy: 0.825 - ETA: 12s - loss: 0.4143 - accuracy: 0.825 - ETA: 11s - loss: 0.4136 - accuracy: 0.826 - ETA: 10s - loss: 0.4131 - accuracy: 0.826 - ETA: 9s - loss: 0.4124 - accuracy: 0.826 - ETA: 8s - loss: 0.4118 - accuracy: 0.82 - ETA: 8s - loss: 0.4114 - accuracy: 0.82 - ETA: 7s - loss: 0.4109 - accuracy: 0.82 - ETA: 6s - loss: 0.4103 - accuracy: 0.82 - ETA: 5s - loss: 0.4097 - accuracy: 0.82 - ETA: 4s - loss: 0.4091 - accuracy: 0.82 - ETA: 4s - loss: 0.4089 - accuracy: 0.82 - ETA: 3s - loss: 0.4084 - accuracy: 0.82 - ETA: 2s - loss: 0.4079 - accuracy: 0.82 - ETA: 1s - loss: 0.4073 - accuracy: 0.82 - ETA: 0s - loss: 0.4067 - accuracy: 0.82 - 209s 13ms/sample - loss: 0.4061 - accuracy: 0.8299 - val_loss: 0.4455 - val_accuracy: 0.8395\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(encoded,label,batch_size=batch_size, epochs=2,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/imdb_keras_lstm_classifier_epochs2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
